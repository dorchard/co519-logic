\documentclass{article}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[table,x11names]{xcolor}
\usepackage{logicproof}
\usepackage{url}
\usepackage{fancyhdr}
\usepackage{enumitem}

% For restatables
\usepackage{thmtools}
\usepackage{thm-restate}
\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}
\newtheorem*{remark}{Remark}
\declaretheorem[name=Exercise,numberwithin=section]{exc}

% Writing
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\eg}{\emph{e.g.}}

\title{\vspace{-3em}CO519 - Theory of Computing - Logic \\
  {\large{Part A : Propositional logic and its natural deduction
      proofs}}}
\author{Dominic Orchard \\
  {\small{School of Computing, University of Kent}}}

\date{Last updated on \today}

\begin{document}
\maketitle

These are the accompanying notes for CO519 (the logic part). They provide
a counterpart to the lectures, but do not replace them; the lectures
will provide content, detail, and discussion not given in these notes.

These notes also provide a counterpart to the course textbook,
\emph{Logic in Computer Science} (by Huth and Ryan) which I
recommend. We will only cover material from the first two chapters due
to the short length of this part of the course. I recommend reading
these chapters, but the assessable material for this course is
covered in lectures and these notes (excluding the appendix); the
textbook contains extra detail which is not assessed, but
worth learning anyway.

If you spot any errors or have suggested edits, the notes are written
in LaTeX and are available on GitHub at
\url{http://github.com/dorchard/co519-logic}. Please fork and submit a
pull request with any suggested changes.

\section{Natural deduction for propositional logic}

Truth tables are a handy way to give meaning to logical operators and
formulas, in terms of truth or falsehood. But they are difficult to
use for reasoning about anything but small formulas since the number
of rows is $2^n$ where $n$ is the number of contingent
formulas. For example, the truth table for
$P \vee (Q \wedge R) \rightarrow (P \vee Q) \wedge (P \vee R)$ has
$2^3 = 8$ rows as there are three contingent formulas: $P$, $Q$, and
$R$ whose truth or falsehood determines the truth or falsehood of the
overall formula. Calculating even this modest truth table takes some
significant calculation to enumerate all possibilities.

Instead, logicians have constructed formal languages (calculi) for
building complex chains of reasoning (proofs) in a more
compact form. In this course, we use the \emph{natural deduction} calculus
due to 20$^{th}$ century logicians such as Gerhard Gentzen
(who formulated natural deduction in 1934) and Dag Pravitz who
promoted this style in the 1960s (and converted
various other results of Gentzen into the natural deduction style).

Natural deduction provides a system of \emph{inference rules} which
explain how to construct and deconstruct formulas to build
a logical argument. These rules represent the derivation of one formula
(the \emph{conclusion}) from several other formulas that are assumed or known to be true
(the \emph{premises}) via the notation:
%
\begin{equation*}
  \dfrac{\textit{premise}_1 \ldots \quad \ldots \textit{premise}_n}
        {\textit{conclusion}}
    \; {(\textit{label})}
\end{equation*}
%
Each logical operator (like conjunction $\wedge$ and
disjunction $\vee$), will have one or more rules for \emph{introducing}
that operator (deriving a conclusion using that operator) and one or
more rules for \emph{eliminating} that operator (deriving a conclusion from a formula
using that operator). These rules can be stacked together to form a
logical argument: \emph{a proof}, which looks like the following:

\begin{equation*}
\dfrac{\dfrac{P_1 \quad P_2}{P_3} \quad P_4}{P_5}
\end{equation*}
%
This isn't an actual concrete proof yet, it's just an example of how
a natural deduction proof looks when you stack together
its inference rules. Informally, we might have something like the
following:
%
\begin{equation*}
\dfrac{\dfrac{\textit{I forgot my coat} \quad \textit{It's
      raining}}{\textit{I get wet}} \quad \textit{My hairdryer broke}}
       {\textit{My hair remains wet}}
\end{equation*}
%
But this isn't always the most helpful format to derive the
proofs. Instead, we'll use a special ``box''-like notation called
Fitch-style which you can find in the recommend reading textbook
\emph{Logic in Computer Science} by Huth and Ryan.
We will still apply the rules of natural deduction, but the Fitch-style
gives us a nice way to layout the proof as we are deriving it.

We will step through the natural deduction rules for the core logical
operators: $\wedge$ (conjunction/and), $\vee$ (disjunction/or),
$\rightarrow$ (implication/if-then), $\neg$ (negation), as well as
truth $\top$ and falsehood/falsity, which is often written in
propositional logic as $\bot$ (pronounced
``bottom'').\footnote{\emph{Bottom} $\bot$ is often used in maths and
  computer science to represent undefined values or behaviour. In
  logic, if have arrived at falsity $\bot$ during a proof then we are
  in a situation where anything could be true as we've arrived at a
  logically inconsistent situation. This is sometimes quite useful for
  doing proofs-by-contradiction, as we will see in
  Section~\ref{sec:negation}.} Note that, in the literature, logical operators
  are sometimes alternatively called \emph{logical connectives}.

\subsection{Properties of formulas}

We will consider three properties that a logical formula may have:

\begin{itemize}[leftmargin=1.5em]
  \item \emph{valid}: a formula which is always true (also
  called a \emph{tautology}). In this part of the course, we will
  mostly prove the validity of formulas. For example, $P \wedge Q
  \rightarrow Q \wedge P$ is true no matter the
  truth/falsehood of $P$ and $Q$. This will be the main property we
  consider in \emph{Part A} (these notes).
%
  \item \emph{satisfiable}: a formula which is true for
  \emph{some} assignments of truth/falsehood to the atoms/variables it contains, \eg{},
  $a \wedge b$ is satisfiable, and the \emph{satisfying assignment} is that
  $a \mapsto \mathsf{T}$ and $b \mapsto \mathsf{T}$. A valid formula
  is trivially satisfiable (true for all assignments).
%
  \item \emph{unsatisfiable}: a formula which is always false (all
  rows in the truth table are false) regardless of assignments to the
  variables/atom, \eg{} $P \wedge \neg (P \vee Q)$. We can
  prove a formula is unsatisfiable by proving its negation is valid.
\end{itemize}

\subsubsection{Entailment and sequents}
\label{sec:entailment}

Suppose we have a set of formulas $P_1, \ldots, P_n$ from which we
want to prove $Q$ by applying the rules of a particular logic
(propositional logic here). The formulas $P_1, \ldots, P_n$ are the
premises and $Q$ is our goal conclusion. This is often written using the
following notation called a \emph{sequent}:
%
\begin{equation*}
P_1, \ldots, P_n \vdash Q
\end{equation*}
%
The turnstile symbol $\vdash$ is read as \emph{entails} and the
premises to the left are sometimes call the \emph{context} of assumed
formulas. This is a compact representation of a formula $Q$ along with
any assumptions used to deduce it.

We say this sequent is \emph{valid} if there is a proof that can be
constructed by deriving the conclusion from the premises. For example,
$P \wedge Q \vdash Q \wedge P$ is valid, meaning from $P \wedge Q$
there is a proof of $Q \wedge P$. If we wish to explain that
a sequent is invalid we can write $P \not\vdash Q$ meaning, it
is not valid that $P$ entails $Q$.

When there are no premises, we often drop the $\vdash$, \ie{},
writing something like ``\emph{$(P \wedge Q) \rightarrow P$ is valid}''
instead of ``\emph{$\vdash (P \wedge Q) \rightarrow P$ is
valid}''.

\subsection{Conjunction (``and'')}

Recall the truth table for conjunction:
%
\begin{center}
\begin{tabular}{cc|c}
  $P$ & $Q$ & $P \wedge Q$ \\ \hline
  F & F & F \\
  F & T & F \\
  T & F & F \\
\rowcolor{yellow}  T & T & T
\end{tabular}
\end{center}
%
From this, we see that in order to conclude the truth of $P \wedge Q$
we need the truth of $P$ and the truth of $Q$. This justifies the
following natural deduction rule for \emph{introducing} conjunction:
%
\begin{align*}
  \dfrac{P \qquad Q}
        {P \wedge Q} \; {\wedge_i}
\end{align*}
%
The label is subscripted with `i' for introduction.
That is, given two premises; $P$ is true and $Q$ is true, then
$P \wedge Q$ is true. There is just one introduction rule,
corresponding to the fact that there is only one ``true'' row
for $P \wedge Q$ in the truth table (highlighted in yellow above).

Note that the $P$ and $Q$ are place-holders here for \emph{any
  propositional formula} so we could instantiate the rule, \eg{},
to something like this if we needed it:
%
\begin{equation*}
\dfrac{(P \vee R \rightarrow Q) \quad S}
      {(P \vee R \rightarrow Q) \wedge S} \; {\wedge_i}
\end{equation*}
%
What about elimination?
Reading the highlighted line in the truth table from right-to-left shows how to
\emph{eliminate} a conjunction, \ie{}, what smaller formulas
can we conclude are true if we know that $P \wedge Q$ is true? We get
two rules:
%
\begin{align*}
  \dfrac{P \wedge Q}
        {P} \; {\wedge_{e1}}
  \qquad & \qquad
      \dfrac{P \wedge Q}
        {Q} \; {\wedge_{e2}}
\end{align*}
%
The labels have a subscript `e' for elimination; this convention will
continue.  (\emph{Aside}: If the syntax of the inference rules let us
have multiple conclusions then we could collapse the two eliminations
into one rule, but natural deduction instead has single
conclusions. There are different proof systems which allow
multiple conclusions (like the \emph{sequent calculus}) but we won't cover that here).

Let's write a proof with just these rules by stacking them together.

\begin{example}
\label{exm:assoc-conj}
  For any formula $P$, $Q$, $R$ then $P \wedge (Q \wedge
  R) \vdash (P \wedge Q) \wedge R$ is valid, \ie{} given $P \wedge (Q \wedge
  R)$ we can prove $(P \wedge Q) \wedge R$.
%
\newcommand{\conge}[1]{\wedge_{e#1}}
  \begin{align*}
    \dfrac{
    \dfrac{\dfrac{P \wedge (Q \wedge R)}
    {P}\conge{1}
    \dfrac{\dfrac{P \wedge (Q \wedge R)}
    {Q \wedge R} \conge{2}}{Q} \conge{1}}
    {P \wedge Q} {\wedge_i}
    \dfrac{\dfrac{P \wedge (Q \wedge R)}
    {Q \wedge R} \conge{2}}{R} \conge{2}}
    {(P \wedge Q) \wedge R} {\wedge_i}
  \end{align*}
The root of the tree is our goal $(P \wedge Q) \wedge R$, which is
built from the premises on the line above. These chains of reasoning
go up to the ``leaves'' of the tree, which is the assumed formula
$P \wedge (Q \wedge R)$. At each step (each line) we've applied
either conjunction introduction or one of the conjunction elimination
rules (as can be seen from the labels on the right).
\end{example}
\noindent
The following exercise is to prove the converse of the above property.
%
\begin{restatable}{exc}{assoc}
  \label{exm:assoc}
  Prove that $(P \wedge Q) \wedge R \vdash P \wedge (Q \wedge R)$ is
  valid by instantiating and stacking together inference rules.
\end{restatable}
%
This proof, and the one above, together imply that conjunction
$\wedge$ is \emph{associative}, \ie{},
$P \wedge (Q \wedge R) = (P \wedge Q) \wedge R$.

\paragraph{Fitch-style proof}
So far we have constructed proofs by stacking natural
deduction inference rules on top of each other. This leads us towards a
\emph{bottom-up} proof strategy starting with the goal and working up
towards the premises. In this course we are going to mostly use a
\emph{top-down} approach called ``Fitch-style''. This style begins
with assumptions, numbers each line of a proof, and uses indentation
and boxes to represent sub-proofs and the scope of their assumptions.

The above proof is rewritten in the following way in Fitch notation:
%
  \begin{logicproof}{2}
    P \wedge (Q \wedge R) & premise \\
    P                     & $\wedge_{e1}$ 1 \\
    Q \wedge R            & $\wedge_{e2}$ 1 \\
    Q                     & $\wedge_{e1}$ 3 \\
    R                     & $\wedge_{e2}$ 3 \\
    P \wedge Q            & $\wedge_i$ 2, 4 \\
    (P \wedge Q) \wedge R & $\wedge_i$ 6, 5 $\quad \Box$
  \end{logicproof}
%
  The proof follows in a number of linear steps. On the left we number
  each line of the argument. On the right, we explain which rule was
  applied to which formula, \eg{}, on the second line we have
  applied conjunction elimination $\wedge_{e1}$ to line $1$ to get the
  formula $P$. Or for example, on line 6, conjunction introduction is
  applied to lines 2 and 4 to get $P \wedge Q$.  We finish on line
  7 with our goal, which is marked with $\Box$ which a way of
  saying the proof is finished and we've reached our goal
  (the symbol means $Q.E.D$ which is an abbreviation of
  \emph{quod erat demonstrandum}, Latin for ``what was to be
  demonstrated'').

We haven't used any sub-proofs yet (which have a box drawn around
them); these appear in the next subsection on implication.

 \textbf{Order of numbers in labels} $\;$
Note that the order of the line numbers in labels tells us the order
of the premises to a natural deduction rule and so the order is
important. For example, line 6 above applies ($\wedge_i$ 2, 4) to
introduce $P \wedge Q$, but if it was actually ($\wedge_i$ 4, 2) we
would be introducing $Q \wedge P$ which is not our intended goal.

\begin{restatable}{exc}{andReproof}
Rewrite your proof to Exercise~\ref{exm:assoc} using
Fitch style.
\end{restatable}

\begin{remark}(\textbf{important})
Depending on what is being proved, a top-down approach (starting
from the premises) or bottom-up approach (starting
from the goal/conclusion) can be easier. In practice, if you are
stuck it can help to start \emph{at both ends} and work towards the
middle. You can do this by putting the goal near a bottom of a piece
of paper, giving enough space to meet in the middle.

It doesn't matter if things get messy-- the primary goal is to reach a
proof. You can rewrite it afterwards to be more clear; you should
do so in your class work and assessments.
\end{remark}

\subsection{Implication}

Recall the truth table for implication:
%
\begin{center}
\begin{tabular}{cc|c}
  $P$ & $Q$ & $P \rightarrow Q$ \\ \hline
  \rowcolor{yellow} F & F & T \\
  \rowcolor{yellow} F & T & T \\
  T & F & F \\
  \rowcolor{yellow} T & T & T
\end{tabular}
\end{center}
%
Implication $P \rightarrow Q$ is interesting because if
$\neg P$ (if $P$ is false) then $Q$ can be true or false, \ie{},
$Q$ can be anything if $P$ is false (the top two lines).

\begin{restatable}{exc}{implProperty}
Recall that $P \rightarrow Q = \neg P \vee Q$. Show this is true
by comparing the truth tables for each side of this equation.
\end{restatable}

As with conjunction, we'll consider the two style of
rule: elimination and introduction.
The elimination rule for implication in natural deduction is:
\begin{align*}
\dfrac{P \rightarrow Q \qquad P}{Q} {\rightarrow_e}
\end{align*}
%
This rule is also known as \emph{modus ponens}.\footnote{\emph{modus
ponens} is short for the Latin phrase \emph{modus ponendo ponens}
which means ``the way that affirms by affirming''.} It says that if
we know $P \rightarrow Q$ and we know $P$ then we know $Q$. You can
verify the soundness of this rule by looking at the truth
table: indeed $Q$ is true when both $P \rightarrow Q$ and $P$ are
true.

There are various other natural deduction rules one might construct by
looking at the truth table-- but this one can be used to derive the
others. The particular set of natural deduction rules we look at was
carefully honed by logicians to provide a kind of ``minimal'' calculus
for proofs.

Introduction of an implication $P \rightarrow Q$ follows from a
\emph{subproof} (which is drawn in a box) which starts with an
assumption of $P$ and ends with $Q$ as a conclusion after any number
of steps. The rule is written as follows:
%
\begin{align*}
\setlength{\arraycolsep}{0em}
\dfrac{\fbox{$\begin{array}{c} P \\ \vdots \\ Q\end{array}$}}
      {P \rightarrow Q} {\rightarrow_i}
\end{align*}
%
Thus subproofs in both tree- and Fitch-style proofs
are of the form:
%
\begin{equation*}
\setlength{\arraycolsep}{0em}
\fbox{$\begin{array}{c} \textit{assumption} \\ \vdots \\[0.5em]
         \textit{conclusion} \end{array}$}
\end{equation*}
%
\begin{remark} (\textbf{important})
%
  When we start a subproof box, the first formula is always an
  assumption. When the box is closed, the assumption does not go away
  but becomes the premise of the implication when applying the
  $\rightarrow_i$ rule.

  \emph{This is an important point}: when proving a theorem we
  have to be careful not to introduce additional assumptions which are
  not part of the theorem. For example, let's say we are proving a
  theorem expressed by a formula $Q$ but in doing so we assume $P$
  but $P$ is not one of $Q$'s assumptions.  Then
  instead we will have proved $P \rightarrow Q$ rather than $Q$.  This
  is something to keep in mind when writing complex
  proofs. The proof system of natural deduction allows us to keep
  track of our assumptions and their eventual inclusion in the final
  result.

  Aside: mechanised proof assistants (software systems in which we
  can write machine-checked proofs, such as \emph{Coq},
  \emph{Isabelle}, \emph{Agda}) have a similar basis to
  natural deduction and give us confidence and precision in writing proofs.
\end{remark}
%
There is an alternate presentation of natural deduction called
\emph{sequent-style natural deduction}, which is described in
Appendix~\ref{app:sequent}, where the inference rules are expressed in
terms of sequents $P_1, \ldots, P_n \vdash Q$. This won't be assessed
on the course, but is worth looking at if you want to read more widely
on logic. Another proof calculus (also due to Gentzen) is the
\emph{sequent calculus} which won't be described here, but there is
plenty of information online.

 \begin{example}
   The following simple formula about conjunction and implication is
   valid: $\vdash (P \wedge Q) \rightarrow (Q \wedge P)$. Here is its proof
   in Fitch-style:
%
\begin{logicproof}{2}
\begin{subproof}
P \wedge Q & assumption    \\
P          & $\wedge_{e1}$ 1 \\
Q          & $\wedge_{e2}$ 1 \\
Q \wedge P & $\wedge_i$ 3, 2
\end{subproof}
P \wedge Q \rightarrow Q \wedge P & $\rightarrow_i$ 1-4 $\qquad \Box$
\end{logicproof}
In the last line, we apply implication introduction and we
label it with the range of the lines of the subproof used (in this
case 1-4).
\end{example}

\begin{remark}
In Example~\ref{exm:assoc-conj} we proved
that given $P \wedge (Q \wedge R)$ then $(P \wedge Q) \wedge
R$. We can turn this into an implication
$P \wedge (Q \wedge R) \rightarrow (P \wedge Q) \wedge R$
simply by using implication introduction on the original
proof.
\end{remark}

\begin{example}
The following is valid:
\begin{align*}
(P \rightarrow (Q \rightarrow R))
\rightarrow
((P \rightarrow Q)
\rightarrow
(P \rightarrow R))
\end{align*}
%
Here is its proof:
%
\begin{logicproof}{5}
 \begin{subproof}
  P \rightarrow (Q \rightarrow R) & ass. \\ % 1
  \begin{subproof}
  P \rightarrow Q   & ass.  \\ % 2
  \begin{subproof}
   P               & ass. \\ % 3
   Q \rightarrow R & $\rightarrow_{e}$ 1, 3 \\ % 4
   Q               & $\rightarrow_{e}$ 2, 3 \\ % 5
   R               & $\rightarrow_{e}$ 4, 5 % 6
  \end{subproof}
   P \rightarrow R & $\rightarrow_{i}$ 3-6 % 7
  \end{subproof}
  (P \rightarrow Q) \rightarrow (P \rightarrow R) & $\rightarrow_{i}$
  2-7 % 8
  \end{subproof}
(P \rightarrow (Q \rightarrow R))
\rightarrow ((P \rightarrow Q) \rightarrow (P \rightarrow R))
& $\rightarrow_i$ 1-8 $\quad \Box$
\end{logicproof}
%
Here we have an example of multiple nesting of subproofs.
(Tip: I proved this by working top-down and bottom-up at the same
time, which was made easier by typing the proof).
\end{example}

Occasionally it is useful to ``copy'' a
formula from earlier in a proof. For example, 
the following proof of $\vdash P \rightarrow P$ copies
a formula from one line of the proof to the other in order
to introduce a trivial implication:
%
\begin{logicproof}{2}
\begin{subproof}
P  & assumption \\
P  & copy 1
\end{subproof}
P \rightarrow P & $\rightarrow_i$ 1-2 $\quad \Box$
\end{logicproof}

\begin{restatable}{exc}{kcombinator}
Prove $P \rightarrow (Q \rightarrow P)$ is valid.
\end{restatable}

\subsubsection{Bi-implication  (``if and only if`'')}

Propositional logic often includes the bi-implication operator
$\leftrightarrow$ also read as ``\emph{if and only if}'' and sometimes
written as \emph{iff} (double f). A bi-implication $P \leftrightarrow Q$ is
equivalent to the conjunction of two implications, pointing in
opposite directions:
%
\begin{align*}
P \leftrightarrow Q \; = \; (P \rightarrow Q) \wedge (Q \rightarrow P)
\end{align*}
%
Therefore to construct or deconstruct a logical
bi-implication one can consider it as ``implemented'' by
conjunction and implication, reducing the number of
introduction/elimination rules that need to be
remembered. Nonetheless, thinking about what these would be
is a nice exercise.

\begin{restatable}{exc}{biimplRules} (optional)
Try to derive your own elimination and introduction rules for
bi-implication. There is usually one introduction and two eliminations.
\end{restatable}



\subsection{Disjunction (``or'')}

Recall the truth table for disjunction (which has the three rows
in which $P \vee Q$ is true):
%
\begin{center}
\begin{tabular}{cc|c}
  $P$ & $Q$ & $P \vee Q$ \\ \hline
  F & F & F \\
\rowcolor{yellow} F & T & T \\
\rowcolor{yellow}  T & F & T \\
\rowcolor{yellow}  T & T & T
\end{tabular}
\end{center}
%
The fact that we can conclude $P \vee Q$ from either $P$
or from $Q$ separately justifies the following two introduction
rules for disjunction in natural deduction:
%
\begin{align*}
  \dfrac{P}
  {P \vee Q} \; {\vee_{i1}}
  \qquad
    \dfrac{Q}
  {P \vee Q} \; {\vee_{i2}}
\end{align*}
%

\begin{example}
Prove $(P \wedge Q) \rightarrow (P \vee Q)$ is valid.

  \begin{logicproof}{2}
    \begin{subproof}
    P \wedge Q & assumption \\
    P          & $\wedge_{e1}$ 1 \\
    P \vee Q   & $\vee_{i1}$ 2
  \end{subproof}
  P \wedge Q \rightarrow P \vee Q & $\rightarrow_i$ 1-3 $\quad \Box$
  \end{logicproof}
  %
  This could have been written equivalently as a natural deduction tree:
  %
  \begin{align*}
   \dfrac{
    \fbox{$\begin{array}{c}
           \dfrac{P \wedge Q}
                 {\dfrac{P}{P \vee Q} {\vee_{i1}}} {\wedge_{e1}}
          \end{array}$}
    }{(P \wedge Q) \rightarrow (P \vee Q)} {\rightarrow_{i}}
  \end{align*}
  %
  This will be the last tree-based proof we see; from now on we'll
  just keep using the Fitch style.
\end{example}
%
What about disjunction elimination? Given the knowledge that $P \vee Q$ is true
then what can be conclude? Either $P$ is true, or $Q$ is true, or both
are true. Therefore, we don't know exactly what true formulas we can derive
from the truth of $P \vee Q$, we just know a selection of
possibilities.


The natural deduction way of eliminating disjunction is to have two
subproofs as premises which are contingent on the assumption of
either $P$ or $Q$:

\begin{align*}
\setlength{\arraycolsep}{0em}
\dfrac{\begin{array}{c} \\ \\[0.7em] P \vee Q\end{array} \quad
\fbox{$\begin{array}{c} P \\ \vdots \\ R\end{array}$}
\quad
\fbox{$\begin{array}{c} Q \\ \vdots \\ R\end{array}$}}{R}
\;
{\vee_e}
\end{align*}

\begin{example}
For any propositions $P, Q, R$ then $(P \wedge Q) \vee (P \wedge
R) \rightarrow P$ is valid.
%
  \begin{logicproof}{3}
    \begin{subproof}
      (P \wedge Q) \vee (P \wedge R) & assumption \\
      \begin{subproof}
        P \wedge Q  & assumption \\
        P           & $\wedge_{e1}$ 2
      \end{subproof}
      \begin{subproof}
        P \wedge R & assumption \\
        P          & $\wedge_{e1}$ 4
      \end{subproof}
        P          & $\vee_{e}$ 1, 2-3, 4-5
    \end{subproof}
    (P \wedge Q) \vee (P \wedge R) \rightarrow P & $\rightarrow_{i}$,
    1-6 $\quad \Box$
  \end{logicproof}
  You can see that the application of disjunction elimination $\vee_e$
  involves three things: a disjunctive formula (line 1) and two
  subproofs (lines 2-3 and lines 4-5) which respectively assume the two subformulas of
  disjunction and conclude with the same formula ($P$), which forms the
  conclusion of the subproof on line 6.
\end{example}

\begin{restatable}{exc}{orassoc}
  Prove $P \vee Q \rightarrow Q \vee P$ is valid.
\end{restatable}

\begin{remark}
  From looking at the truth table for disjunction, one might wonder
  why disjunction elimination does not look like:
  %%
\begin{align*}
\setlength{\arraycolsep}{0em}
\dfrac{\begin{array}{c} \\ \\[0.7em] P \vee Q\end{array} \quad
\fbox{$\begin{array}{c} P \\ \vdots \\ R\end{array}$}
\quad
\fbox{$\begin{array}{c} Q \\ \vdots \\ R\end{array}$}
  \quad
  \fbox{$\begin{array}{c} P \wedge Q \\ \vdots \\ R\end{array}$}}{R}
{\vee_e}
\end{align*}
  %%
  This would match more closely the idea of reading the truth-table
  ``backwards'' from right-to-left on true values of $P \vee Q$. The
  reason we don't have this is that natural deduction strives for
  minimality and the third subproof with assumption $P \wedge Q$ is
  redundant since if we have $P \wedge Q$ true we can apply
  either the subproof $\fbox{$P \ldots R$}$ or the subproof
  $\fbox{$Q \ldots R$}$ by first applying $\wedge_{e1}$ or
  $\wedge_{e2}$ to the assumption $P \wedge Q$ to get $P$ or $Q$ respectively.
%and the above rule can be derived from the disjunction
%  elimination shown here with just two subproofs:
%  \begin{align*}
%\setlength{\arraycolsep}{0em}
%\dfrac{\begin{array}{c} \\ \\[0.7em] P \vee Q\end{array} \quad
%\Delta = \fbox{$\begin{array}{c} P \\ \vdots \\ R\end{array}$}
%\quad
%\fbox{$\begin{array}{c} Q \\ \vdots \\ R\end{array}$}
%  \quad
%  \fbox{$\begin{array}{c} \dfrac{\dfrac{P \wedge Q}{P}
%           {\wedge_{e1}}}{\Delta} \\ \vdots \\ R \end{array}$}}{R}
%{\vee_e}
%\end{align*}
%  That is, if we name the subproof of $\fbox{$P \ldots R$}$ as $\Delta$ and
%  then we can reuse this along with conjunction elimination to get the
%  proof for $\fbox{$P \wedge Q \ldots R$}$. In fact, there is another way to
%  derive this, where we reuse the subproof of $\fbox{$Q \ldots R$}$ and use
%  $\wedge_{e2}$ to build a proof of $\fbox{$P \wedge Q \ldots R$}$.
  \end{remark}

\subsection{Negation}
\label{sec:negation}

Negation introduction and elimination are given by:
%
\begin{align*}
\setlength{\arraycolsep}{0em}
\dfrac{
\fbox{$\begin{array}{c} P \\ \vdots \\ \bot\end{array}$}}
      {\neg P} \; {\neg_i}
\qquad\quad
\dfrac{P \qquad \neg P}{\bot} {\neg_e}
\end{align*}
%
Introduction says that given a proof that assumes $P$ but ends in
falsehood $\bot$ then we know $\neg P$, this is similar to the notion of
\emph{proof by contradiction}, which is derived from this (see below).

Elimination states that given a proof of $P$ and a simultaneous proof of
$\neg P$ then we conclude falsehood $\bot$, \ie{}, we have a
logical inconsistency on our hands and so end up proving false:
$P$ and $\neg P$ cannot both be true at the same time.

\begin{example}
For all $P, Q$ then $P \rightarrow Q \vdash \neg Q \rightarrow
\neg P$.
%
\begin{logicproof}{3}
    P \rightarrow Q  & assumption \\
    \begin{subproof}
      \neg Q        & assumption \\
      \begin{subproof}
        P           & assumption \\
        Q           & $\rightarrow_{e}$ 1, 3 \\
        \bot        & $\neg_{e}$ 2, 4
      \end{subproof}
      \neg P       & $\neg_i$ 3-5
     \end{subproof}
    \neg Q \rightarrow \neg P & $\rightarrow_i$ 2-6 $\qquad \Box$
\end{logicproof}
\end{example}

\begin{remark}
  This example is often given as a derived inference rule called
\emph{modus tollens}\footnote{\emph{modus
tollens} is short for the Latin phrase \emph{modus tollendo tollens}
which means ``the way that denies by denying''.}
that is similar to modus ponens (implication elimination):
%
\begin{align*}
\dfrac{P \rightarrow Q \quad \neg Q}
      {\neg P} \; {\emph{mt}}
\end{align*}
%
If an inference rule can be derived from others we say it is
\emph{admissible}. The system of rules we take as the basis for
natural deduction reasoning contains no admissible rules.
\end{remark}

\begin{remark}
  If we want to prove a formula $P$ is unsatisfiable then we can
  instead prove that $\neg P$ is valid (always true), hence proving
  that $P$ is unsatisfiable (always false).
\end{remark}

\begin{restatable}{exc}{disproveEx}
Prove that $P \wedge \neg (P \vee Q)$ is unsatisfiable.
\end{restatable}

\begin{remark}
  Some formulae are not valid, \eg{}, $P \rightarrow \neg P$, which
  can be seen from drawing its true table. However, this formula is
  \emph{satisfiable}, if $P$ is false then $P \rightarrow \neg P$ is
  true. Natural deduction does not help us to prove
  satisfiability. Part B will look at algorithmic approaches to
  deciding satisfiability.
\end{remark}

\subsubsection{Double negation}

A special rule holds called \emph{double-negation elimination} which
allows us to remove double negations on a proposition:
%
\begin{align*}
\dfrac{\neg \neg P}{P} \;\; {\neg\neg_e}
\end{align*}
%
\begin{example}
The principle of \emph{proof by contradiction} is represented by
following the derived inference rule:
%
\begin{equation*}
\setlength{\arraycolsep}{0em}
\dfrac{
\fbox{$\begin{array}{c} \neg P \\ \vdots \\ \bot\end{array}$}}
      {P} \; {\textsc{PBC}}
\end{equation*}
%
That is, if we assume $\neg P$ and conclude $\bot$, then we have $P$.
To show how to derive this, let the subproof in the above rule be
called $\Delta$, then we construct the following proof:
%
\begin{logicproof}{2}
\begin{subproof}
\neg P & ass. \\
\Delta & $\vdots$ \\
\bot &
\end{subproof}
\neg \neg P & $\neg_i$ 1-3 \\
P           & $\neg\neg_e$ 4
\end{logicproof}
Of course, $\Delta$ might be much longer than 3 lines, but we use
the numbering in the above proof for clarity.
\end{example}

\subsection{Truth and falsity}

If we have $\bot$ (false), then we can derive any formula:
%
\begin{align*}
\dfrac{\bot}{P} \; {\bot_e}
\end{align*}
%
There is no $\bot$ introduction as such, though $\neg_{e}$
provides a kind of $\bot$ introduction (from conflicting formula).
Dually, we can always introduce truth from no premises, but there
is no elimination:
%
\begin{align*}
\dfrac{\qquad}{\top} \; {\top_i}
\end{align*}
%

\subsection{A further derived rule: Law of Excluded Middle}

An interesting rule that we can derive in the propositional logic
is called the \emph{Law of Excluded Middle} or LEM for short. It says
that for any formula $P$ we have the following valid rule:
%
\begin{equation*}
\dfrac{\qquad\qquad}{P \vee \neg P} \textsc{lem}
\end{equation*}
%
\ie{}, whatever $P$ is, then either $P$ is true or $\neg P$ is true. Here
is its derivation:
%
\begin{logicproof}{2}
  \begin{subproof}
    \neg (P \vee \neg P) & ass. \\
    \begin{subproof}
      P  & ass. \\
      P \vee \neg P & $\vee_{i1}$ 2 \\
      \bot          & $\neg_e$ 3, 1
    \end{subproof}
    \neg P          & $\neg_i$ 2-4 \\
    P \vee \neg P   & $\vee_{i2}$ 5 \\
    \bot            & $\neg_e$ 6, 1
  \end{subproof}
\neg \neg (P \vee \neg P) & $\neg_i$ 1-7 \\
P \vee \neg P & $\neg\neg_e$ 8 $\;\;\Box$
\end{logicproof}
%
This rule can be useful in particular proofs.

\begin{restatable}{exc}{lemp}
Using LEM, prove that $\,P \rightarrow Q \vdash \neg P \vee Q\,$ is valid.
\end{restatable}

\paragraph{Aside: constructive vs non-constructive logic}

In this course, we study a particular kind of propositional logic
called \emph{classical} or \emph{non-constructive}
logic. Another variant is known as \emph{intuitionistic} or
\emph{constructive} logic which has a slightly different
set of inference rules: $\neg\neg_e$ is not included. By removing
double-negation elimination we can no longer derive
proof-by-contradiction or LEM.

The central principle of constructive logic is to reason about
\emph{proof} rather than \emph{truth} (as in classical logic). In
constructive logic, a
formula $P$ represents the proof of formula $P$: a mathematical object
witnessing the truth of $P$ which we can separately analyse. The
inference rules of natural deduction are now about preserving proof
rather than truth, \eg{}, conjunction elimination says given a proof
of $P \wedge Q$ then we can prove $P$.

In constructive logic, $\neg\neg_e$ is rejected since it would mean we
can get a proof of $P$ from a proof of the negation of the negation of
$P$, but this proof is not a proof of $P$. This is particularly
troublesome when using $\neg\neg_e$ to prove LEM. If LEM was allowed
in constructive logic, then for any formula $P$ we can construct
either a proof of $P$ or a proof of $\neg P$. But what is that proof
and where has it come from? Out of thin air! (LEM has no
premises). The essence of constructive logic is to disallow such
things so that we always know we have a concrete proof for our
formulas, constructed from proofs of its subformulas or premises. Section 1.2.5
of the Huth and Ryan course textbook gives some more detail and shows
an example mathematical proof about rational numbers in classical logic
which cannot be proved constructively.

Constructive logics are useful because they correspond to type systems
in functional programming: a result known as the \emph{Curry-Howard
  correspondence}. Unfortunately, we will not have time to study that here.

\newpage

\section{Collected rules of natural deduction}

\vspace{2em}

\setlength{\tabcolsep}{1.54em}
\renewcommand{\arraystretch}{1}
\begin{tabular}{r||c|c}
 & \textit{Introduction} & \textit{Elimination} \\[0.5em] \hline \hline
  $\wedge$
& \rule{0cm}{0.75cm} $\dfrac{P \qquad Q}
         {P \wedge Q} \; {\wedge_i}$
& $\dfrac{P \wedge Q}
        {P} \; {\wedge_{e1}}
  \qquad
      \dfrac{P \wedge Q}
  {Q} \; {\wedge_{e2}}$ \\[1.25em] \hline
  %%%%%%%%%%%
  $\vee$
& $\begin{array}{c}\dfrac{P}
  {P \vee Q} \; {\vee_{i1}}
  \qquad
    \dfrac{Q}
  {P \vee Q} \; {\vee_{i2}}\\[3.25em]\end{array}$
& \rule{0cm}{2.15cm} $\setlength{\arraycolsep}{0em}
\dfrac{\begin{array}{c} \\ \\[0.7em] P \vee Q\end{array} \quad
\fbox{$\begin{array}{c} P \\ \vdots \\ R\end{array}$}
\quad
\fbox{$\begin{array}{c} Q \\ \vdots \\ R\end{array}$}}{R}
\;
{\vee_e}$ \\[1em] \hline
  %%%%%%%%%%%
  $\rightarrow$
 & \rule{0cm}{2.15cm} $\setlength{\arraycolsep}{0em}\dfrac{\fbox{$\begin{array}{c} P \\ \vdots \\ Q\end{array}$}}
      {P \rightarrow Q} {\rightarrow_i}$
 & $\begin{array}{c}\dfrac{P \rightarrow Q \qquad P}{Q}
      {\rightarrow_e} \\[3em]\end{array}$
  \\[1em] \hline
  $\neg$
 & \rule{0cm}{2.15cm}
   $\setlength{\arraycolsep}{0em}\dfrac{\fbox{$\begin{array}{c} P \\ \vdots \\ \bot\end{array}$}}
  {\neg P} \; {\neg_i}$
 & $\begin{array}{c}\dfrac{P \qquad \neg P}{\bot} {\neg_e} \\[3em] \end{array}$ \\[0.5em] \hline
  $\top$
& \rule{0cm}{0.75cm}$\dfrac{\qquad}{\top} \; {\top_i}$ \\[1.25em] \hline
  $\bot$
 & & \rule{0cm}{0.75cm}$\dfrac{\bot}{P} \; {\bot_e}$ \\[1.25em] \hline
   $\neg\neg$
 & \rule{0cm}{0.75cm}{\textcolor{gray}{(derivable: $\dfrac{P}{\neg \neg P} \;\; {\neg\neg_i}$)}}  & \rule{0cm}{0.75cm}$\dfrac{\neg \neg P}{P} \;\; {\neg\neg_e}$
\end{tabular}

\vspace{3em}

\noindent
These are all the rules we have and need for propositional proofs. You
should aim to know all of the above rules by the end of the
course/exam.

We derived other useful inference rules from these rules, like modus
tollens, proof-by-contradiction, and law-of-excluded-middle. They
are useful to know but the table above gives the essential rules
for propositional proofs.

\newpage

\section{Exercises}

  This section collects together the exercises given so far. They may
  not all be covered in lectures, so they provide useful
  additional examples to practise on.

  \assoc*
  \andReproof*
  \implProperty*
  \kcombinator*
  \biimplRules*
  \orassoc*
  \disproveEx*
  \lemp*

\appendix

\section{Sequent-style natural deduction}
\label{app:sequent}

Recall from Section~\ref{sec:entailment} that 
a sequent is a compact representation of a formula $P$ along with
any assumptions used to deduce it, written in the form:
%
\begin{equation*}
P_1, \ldots, P_n \vdash P
\end{equation*}
%
The turnstile symbol $\vdash$ is read as \emph{entails} and the premises to the left are
called the \emph{context} of assumed formulas. The right-hand side is
the \emph{conclusion}.  For example, the following
judgment captures the idea of conjunction introduction:
%
\begin{equation*}
P, Q \vdash P \wedge Q
\end{equation*}
%
An alternate formulation of natural deduction gives the usual
introduction and elimination rules in sequent form, making explicit
the assumption context of the formula. This sequent-style of natural
deduction is not assessed in CO519, but is included here for
completeness and to help with any wider reading.

A key rule that was implicit in the previous formulation of natural
deduction is the use of an assumption as a formula. This is usually
called the \emph{axiom} rule:
%
\begin{align*}
\dfrac{\qquad}{\Gamma, P \vdash P} \; (\textit{axiom})
\end{align*}
%
This says that given some context with an assumption $P$ and any other
assumptions, represented by the Greek symbol $\Gamma$ (uppercase
gamma)\footnote{Gamma $\Gamma$ is the third letter of the Greek
  alphabet, corresponding to Latin $C$, hence $\Gamma$ for
  ``Context''. Logicians like Greek as it gives them lots more symbols
  to use to represent things tersely. These are conventions which take
  some getting used to.} then we can conclude $P$.  This is similar to
the idea of copying in Fitch-style proofs.

The order of assumptions on the left of $\vdash$ is not important (we
can freely move assumptions around).  The sequent style captures that
there may be other assumptions $\Gamma$ in scope.  A meta rule says
that we can add arbitrary redundant assumptions into our context
(called \emph{weakening}):
%
\begin{equation*}
  \dfrac{\Gamma \vdash A}
        {\Gamma, \Gamma' \vdash A} \; (\textit{weaken})
  \end{equation*}
  %
This is useful when we have two subproofs that we want to
make have the same set of assumptions (see below). The rest
of the rules are the introduction and elimination rules
for operators.

\paragraph{Conjunction}
%
\begin{align*}
\dfrac{\Gamma \vdash P \quad \Gamma \vdash Q}{\Gamma \vdash P \wedge
  Q} {\wedge_i}
\quad
\dfrac{\Gamma \vdash P \wedge Q}{\Gamma \vdash P} {\wedge_{e1}}
\quad
\dfrac{\Gamma \vdash P \wedge Q}{\Gamma \vdash Q} {\wedge_{e2}}
\end{align*}
%
These rules are very similar to the previously shown natural
deduction rules, but they now carry a context of assumptions
$\Gamma$. If the context doesn't match between
two premises, weakening (above) can be applied so that they match.

\paragraph{Disjunction}

\begin{align*}
\dfrac{\Gamma \vdash P}
      {\Gamma \vdash P \vee Q}  {\vee_{i1}}
\quad
\dfrac{\Gamma \vdash Q}
      {\Gamma \vdash P \vee Q} {\vee_{i2}}
\quad
\dfrac{\Gamma \vdash P \vee Q
  \quad \Gamma, P \vdash R
  \quad \Gamma, Q \vdash R}
      {\Gamma \vdash R} {\vee_{e}}
\end{align*}
%
The disjunction elimination rule is much less unruly than the previous
formulation, but has the same meaning. Note, we are now extending the
context of assumptions with $P$ and $Q$ in the last two premises.

\paragraph{Implication}

\begin{align*}
\dfrac{\Gamma \vdash A \rightarrow B \quad \Gamma \vdash A}
      {\Gamma \vdash B} {\rightarrow_e}
\quad
\dfrac{\Gamma, A \vdash B}{\Gamma \vdash A \rightarrow B}
 {\rightarrow_i}
\end{align*}
As an example, here is the proof of $P \wedge Q \rightarrow P \vee Q$
in this style:
%
\newcommand{\pAB}{\dfrac{}{P \wedge Q \vdash P \wedge Q} {\textit{axiom}}}
\begin{align*}
  \dfrac{
  \dfrac{\dfrac{\pAB}{P \wedge Q \vdash P} {\wedge_{e1}}}
  {P \wedge Q \vdash P \vee Q} {\vee_{i1}}}
  {\vdash (P \wedge Q) \rightarrow (P \vee Q)} {\rightarrow_{i}}
\end{align*}

\paragraph{Negation,  falsity, and truth}

\begin{align*}
  \dfrac{\Gamma, P \vdash \bot}{\Gamma \vdash \neg P} {\neg_i}
  \quad
  \dfrac{\Gamma \vdash P \; \Gamma \vdash \neg P}{\Gamma \vdash \bot} {\neg_e}
  \quad
  \dfrac{\Gamma \vdash \neg}{\Gamma \vdash P} {\bot_e}
  \quad
  \dfrac{}{\Gamma \vdash \top} {\top_i}
\end{align*}
%

\end{document}
